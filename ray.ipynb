{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEk1VnBfyw3X"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install sentence_transformers\n",
        "!pip install faiss-cpu\n",
        "!pip install openai\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn4W_JZZzxYV"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AXqnL5ve2G_z",
        "outputId": "0c610a41-dd75-4b12-b810-f278f534a3a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-0.3.29-py3-none-any.whl (396 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/396.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m389.1/396.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.5.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-13 06:02:59,001\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::process_shard()\u001b[39m (pid=1576, ip=172.28.0.12)\n",
            "ModuleNotFoundError: No module named 'chromadb'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::process_shard()\u001b[39m (pid=1576, ip=172.28.0.12)\n",
            "  File \"<ipython-input-10-0ccce8b293c0>\", line 9, in process_shard\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\", line 534, in from_documents\n",
            "    return cls.from_texts(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\", line 489, in from_texts\n",
            "    chroma_collection = cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\", line 84, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Could not import chromadb python package. Please install it with `pip install chromadb`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting requests>=2.28 (from chromadb)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0,>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.11)\n",
            "Collecting hnswlib>=0.7 (from chromadb)\n",
            "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-13 06:03:01,002\tERROR worker.py:408 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::process_shard()\u001b[39m (pid=1621, ip=172.28.0.12)\n",
            "ModuleNotFoundError: No module named 'chromadb'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::process_shard()\u001b[39m (pid=1621, ip=172.28.0.12)\n",
            "  File \"<ipython-input-10-0ccce8b293c0>\", line 9, in process_shard\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\", line 534, in from_documents\n",
            "    return cls.from_texts(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\", line 489, in from_texts\n",
            "    chroma_collection = cls(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/langchain/vectorstores/chroma.py\", line 84, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Could not import chromadb python package. Please install it with `pip install chromadb`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb)\n",
            "  Downloading clickhouse_connect-0.6.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (966 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m966.7/966.7 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.8.1)\n",
            "Collecting fastapi==0.85.1 (from chromadb)\n",
            "  Downloading fastapi-0.85.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m257.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.7.1)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.65.0)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\n",
            "Collecting starlette==0.20.4 (from fastapi==0.85.1->chromadb)\n",
            "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette==0.20.4->fastapi==0.85.1->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
            "Collecting importlib-metadata (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.16)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4 (from clickhouse-connect>=0.5.7->chromadb)\n",
            "  Downloading lz4-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.11.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.4)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (428 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.8/428.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->clickhouse-connect>=0.5.7->chromadb) (3.15.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb) (1.1.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp310-cp310-linux_x86_64.whl size=2119770 sha256=3223861eda08da426fd34df80806c4faa75b528d7551065808a61a49f9a51755\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/ae/ec/235a682e0041fbaeee389843670581ec6c66872db856dfa9a4\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: monotonic, zstandard, websockets, uvloop, requests, python-dotenv, pulsar-client, overrides, lz4, importlib-metadata, humanfriendly, httptools, hnswlib, h11, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, clickhouse-connect, onnxruntime, fastapi, chromadb\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 chromadb-0.3.29 clickhouse-connect-0.6.6 coloredlogs-15.0.1 fastapi-0.85.1 h11-0.14.0 hnswlib-0.7.0 httptools-0.6.0 humanfriendly-10.0 importlib-metadata-6.8.0 lz4-4.3.2 monotonic-1.6 onnxruntime-1.15.1 overrides-7.3.1 posthog-3.0.1 pulsar-client-3.2.0 python-dotenv-1.0.0 requests-2.31.0 starlette-0.20.4 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 zstandard-0.21.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOSw22j1y-Vy",
        "outputId": "7e34d529-1332-4141-cf08-15497d94db6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.12.1-py3-none-any.whl (254 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/254.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m245.8/254.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.8/254.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGKeLcBWzeEC",
        "outputId": "66d7dcd6-dfac-40a1-9486-9211d7d2e856"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-2.5.1-cp310-cp310-manylinux2014_x86_64.whl (56.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from ray) (23.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.12.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.0.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (23.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.27.1)\n",
            "Collecting grpcio<=1.51.3,>=1.42.0 (from ray)\n",
            "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from ray) (1.22.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.19.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4)\n",
            "Installing collected packages: grpcio, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.56.0\n",
            "    Uninstalling grpcio-1.56.0:\n",
            "      Successfully uninstalled grpcio-1.56.0\n",
            "Successfully installed grpcio-1.51.3 ray-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUP5fIH6xdOO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import ray\n",
        "from langchain.document_loaders import ReadTheDocsLoader\n",
        "from langchain.embeddings.base import Embeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from sentence_transformers import SentenceTransformer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJwTjSeTx1Az"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaOQ6_lIyL2K"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import create_qa_with_sources_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2A8fVHsy7hz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuGtbu-uxfcD",
        "outputId": "526d264f-b532-42ea-a7e3-2108ec8bdb40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-13 06:02:19,209\tINFO worker.py:1636 -- Started a local Ray instance.\n"
          ]
        }
      ],
      "source": [
        "FAISS_INDEX_PATH = \"faiss_index_fast\"\n",
        "db_shards = 8\n",
        "ray.init()\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"/content/data_Anlasma_Metni.pdf\")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTAyLKtXxibi"
      },
      "outputs": [],
      "source": [
        "@ray.remote(num_gpus=1)\n",
        "def process_shard(shard):\n",
        "    print(f\"Starting process_shard of {len(shard)} chunks.\")\n",
        "    st = time.time()\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    et = time.time() - st\n",
        "    print(f\"Loading embeddings took {et} seconds.\")\n",
        "    st = time.time()\n",
        "    result = FAISS.from_documents(shard, embeddings)\n",
        "    et = time.time() - st\n",
        "    print(f\"Shard completed in {et} seconds.\")\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_rhUpCcxfYx",
        "outputId": "b2e58ed1-cf9c-4a1e-cdb9-088af0ce23f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading documents ...\n",
            "Time taken: 0.09624838829040527 seconds. 27 chunks generated\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "print(\"Loading documents ...\")\n",
        "docs = loader.load()\n",
        "# Theoretically, we could use Ray to accelerate this, but it's fast enough as is.\n",
        "chunks = text_splitter.create_documents(\n",
        "    [doc.page_content for doc in docs], metadatas=[doc.metadata for doc in docs]\n",
        ")\n",
        "et = time.time() - st\n",
        "print(f\"Time taken: {et} seconds. {len(chunks)} chunks generated\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2zs3tHtxfVq",
        "outputId": "97941493-5d93-47b1-a115-c20c37953865"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading chunks into vector store ... using 8 shards\n",
            "\u001b[2m\u001b[36m(process_shard pid=6296)\u001b[0m Starting process_shard of 4 chunks.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(process_shard pid=6296)\u001b[0m Loading embeddings took 0.014208078384399414 seconds.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(process_shard pid=3632)\u001b[0m Loading embeddings took 0.014208078384399414 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6296)\u001b[0m Shard completed in 1.3723869323730469 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6347)\u001b[0m Starting process_shard of 4 chunks.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6347)\u001b[0m Loading embeddings took 0.017510414123535156 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6347)\u001b[0m Shard completed in 1.7929306030273438 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6409)\u001b[0m Starting process_shard of 4 chunks.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6409)\u001b[0m Shard completed in 1.04929518699646 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6409)\u001b[0m Shard completed in 1.04929518699646 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6462)\u001b[0m Loading embeddings took 0.009847879409790039 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6512)\u001b[0m Starting process_shard of 3 chunks.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(process_shard pid=6462)\u001b[0m Loading embeddings took 0.013473033905029297 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6512)\u001b[0m Shard completed in 1.2837824821472168 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6512)\u001b[0m Shard completed in 1.2837824821472168 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6563)\u001b[0m Starting process_shard of 3 chunks.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6563)\u001b[0m Loading embeddings took 0.015077352523803711 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6621)\u001b[0m Starting process_shard of 3 chunks.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6563)\u001b[0m Loading embeddings took 0.009340047836303711 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6621)\u001b[0m Shard completed in 0.6592807769775391 seconds.\n",
            "\u001b[2m\u001b[36m(process_shard pid=6668)\u001b[0m Loading embeddings took 0.009447813034057617 seconds.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "Shard processing complete. Time taken: 33.9968466758728 seconds.\n",
            "Merging shards ...\n"
          ]
        }
      ],
      "source": [
        "# Stage two: embed the docs.\n",
        "print(f\"Loading chunks into vector store ... using {db_shards} shards\")\n",
        "st = time.time()\n",
        "shards = np.array_split(chunks, db_shards)\n",
        "futures = [process_shard.remote(shards[i]) for i in range(db_shards)]\n",
        "results = ray.get(futures)\n",
        "et = time.time() - st\n",
        "print(f\"Shard processing complete. Time taken: {et} seconds.\")\n",
        "\n",
        "st = time.time()\n",
        "print(\"Merging shards ...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CPJfRuSxfS8",
        "outputId": "4de0609a-0d5a-4c26-ea58-652ae0a644cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged in 49.6120183467865 seconds.\n"
          ]
        }
      ],
      "source": [
        "db = results[0]\n",
        "for i in range(1, db_shards):\n",
        "    db.merge_from(results[i])\n",
        "et = time.time() - st\n",
        "print(f\"Merged in {et} seconds.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMG4gsVZxfQV",
        "outputId": "5ff102f2-354e-4c90-c056-123f2f13d23a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving faiss index\n",
            "Saved in: 0.002652406692504883 seconds.\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "print(\"Saving faiss index\")\n",
        "db.save_local(FAISS_INDEX_PATH)\n",
        "et = time.time() - st\n",
        "print(f\"Saved in: {et} seconds.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khBDy2iuxfNL"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo-4G6wpxfKT"
      },
      "outputs": [],
      "source": [
        "qa_chain = create_qa_with_sources_chain(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMuSbplHySFC"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\\n",
        "Make sure to avoid using any unclear pronouns.\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
        "condense_question_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=CONDENSE_QUESTION_PROMPT,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wxdr_Jtn6L1r"
      },
      "outputs": [],
      "source": [
        "qa_chain_pydantic = create_qa_with_sources_chain(llm, output_parser=\"pydantic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AipV48j_6SsK"
      },
      "outputs": [],
      "source": [
        "doc_prompt = PromptTemplate(\n",
        "    template=\"Content: {page_content}\\nSource: {source}\",\n",
        "    input_variables=[\"page_content\", \"source\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6P7VWry6IFa"
      },
      "outputs": [],
      "source": [
        "final_qa_chain = StuffDocumentsChain(\n",
        "    llm_chain=qa_chain,\n",
        "    document_variable_name=\"context\",\n",
        "    document_prompt=doc_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5hHAxgs0IY6"
      },
      "outputs": [],
      "source": [
        "qa = ConversationalRetrievalChain(\n",
        "    question_generator=condense_question_chain,\n",
        "    retriever=db.as_retriever(),\n",
        "    memory=memory,\n",
        "    combine_docs_chain=final_qa_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-gqHeq_yR7C"
      },
      "outputs": [],
      "source": [
        "query = \"yetkili bahkemeler\"\n",
        "result = qa({\"question\": query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1G_fndByR3i",
        "outputId": "f37f957e-9e8f-4df3-9a21-225571b05d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'yetkili bahkemeler',\n",
              " 'chat_history': [HumanMessage(content='yetkili bahkemeler', additional_kwargs={}, example=False),\n",
              "  AIMessage(content='{\\n  \"answer\": \"İhtilaf halinde yetkili ve görevli mahkeme İstanbul Mahkemeleri ve İcra Daireleridir.\",\\n  \"sources\": [\"/content/data_Anlasma_Metni.pdf\"]\\n}', additional_kwargs={}, example=False)],\n",
              " 'answer': '{\\n  \"answer\": \"İhtilaf halinde yetkili ve görevli mahkeme İstanbul Mahkemeleri ve İcra Daireleridir.\",\\n  \"sources\": [\"/content/data_Anlasma_Metni.pdf\"]\\n}'}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvMAnTw3yRxz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
